{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import csv\r\n",
    "import pandas as pd\r\n",
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import numpy as np\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def load_file(fileName):\r\n",
    "    dataset = pd.read_table(fileName, header=0, sep=\",\", encoding=\"unicode_escape\")\r\n",
    "    \r\n",
    "    return dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "# preprocess creates the term frequency matrix for the review data set\r\n",
    "def preprocess(data):\r\n",
    "    count_vectorizer = CountVectorizer()\r\n",
    "    data = count_vectorizer.fit_transform(data)\r\n",
    "    #tfidf_data = TfidfTransformer(use_idf=False).fit_transform(data)\r\n",
    "\r\n",
    "    return data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "def learn_model(data,target):\r\n",
    "  \r\n",
    "    classifier = None\r\n",
    "    #Your custom implementation of NaiveBayes classifier will go here.\r\n",
    "    \r\n",
    "    # count vector matrix\r\n",
    "    count_vector = data.toarray()\r\n",
    "    # N, |V|\r\n",
    "    Total_documents, Vocabulary_size = len(count_vector), len(count_vector[0])\r\n",
    "    # print(Total_documents, Vocabulary_size)\r\n",
    "    \r\n",
    "    # get all individual classes\r\n",
    "    classes = list(np.unique(target))\r\n",
    "    # P(c_i)\r\n",
    "    Prob_Classes = np.zeros(len(classes))\r\n",
    "\r\n",
    "    # P(w_i/c_j) - P(each_word / given a class) \r\n",
    "    Prob_wi_by_cj = np.zeros((len(classes),Vocabulary_size))\r\n",
    "\r\n",
    "    #\r\n",
    "    for each_class in range(len(classes)):\r\n",
    "        # count of documents that have been mapped to this category c_j\r\n",
    "        docs_with_c_j = []\r\n",
    "        for doc in range(len(count_vector)):\r\n",
    "            if(target.iloc[doc] == classes[each_class]):\r\n",
    "                docs_with_c_j.append(count_vector[doc])\r\n",
    "        # Prob(c) of given class / P(c_j)\r\n",
    "        Prob_Classes[each_class] = len(docs_with_c_j) / Total_documents\r\n",
    "\r\n",
    "        # calculate the total count of each word\r\n",
    "        #  this is docs_with_c_j below\r\n",
    "        # doc  | word1 word2 word3 ... | class\r\n",
    "        # doc1 |   1    0     1    ... |  c_j\r\n",
    "        # doc2 |   1    0     0    ... |  c_j\r\n",
    "        # doc3 |   0    1     1    ... |  c_j\r\n",
    "        # doc4 |   1    1     0    ... |  c_j\r\n",
    "        #  ...                     ...\r\n",
    "        # = [sum(word1), sum(word2), sum(word3), ... vocab_size]\r\n",
    "        count_wi_by_cj = np.sum(docs_with_c_j, axis=0) # Count(w_i, c_j) for all w_i\r\n",
    "        count_wi_by_cj += 1 # laplace smoothing\r\n",
    "        Sum_Prob_wi_by_cj = np.sum(count_wi_by_cj) # summation(count(w, c_j))\r\n",
    "        Prob_wi_by_cj[each_class] = count_wi_by_cj / Sum_Prob_wi_by_cj # P(w_i | c_j)\r\n",
    "\r\n",
    "    Class_Prob_Dict = dict()\r\n",
    "    for each_class in range(len(classes)):\r\n",
    "        Class_Prob_Dict[classes[each_class]] = Prob_Classes[each_class]\r\n",
    "    \r\n",
    "    classifier = (classes, Class_Prob_Dict, Prob_wi_by_cj) # c's, P(c), P(w_i|c_j)\r\n",
    "\r\n",
    "    return classifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def classify(classifier, testdata):\r\n",
    "    \r\n",
    "    predicted_val=[]\r\n",
    "    #Your code to classify test data using the learned model will go here\r\n",
    "  \r\n",
    "    return predicted_val"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def evaluate(actual_class, predicted_class):\r\n",
    "        \r\n",
    "    accuracy = -1    \r\n",
    "    #Your code to evaluate the model will go here. The code will print overall model's accuracy and precision \r\n",
    "    #and recall for each class label.\r\n",
    "    \r\n",
    "    print(\"The accuracy score is :\",accuracy)\r\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "features = [\"SUMMARY\", \"categories\", \"sub_categories\"]\r\n",
    "\r\n",
    "print(\"Loading data.....\")\r\n",
    "dataset = load_file(\"TextClassification_Data.csv\")\r\n",
    "data,target = dataset[features[0]].fillna(\" \"), dataset[features[1]]\r\n",
    "\r\n",
    "print(\"preprocessing data.....\")\r\n",
    "word_vectors = preprocess(data)\r\n",
    "\r\n",
    "trainingX,testX,trainingY,testY = train_test_split(word_vectors,target,test_size=0.4,random_state=43)\r\n",
    "\r\n",
    "print(\"Learning model.....\")\r\n",
    "model = learn_model(trainingX,trainingY)\r\n",
    "\r\n",
    "print(\"Classifying test data......\")      \r\n",
    "predictedY = classify(model, testX)\r\n",
    "\r\n",
    "print(\"Evaluating results.....\")\r\n",
    "evaluate(testY,predictedY)\r\n",
    "\r\n",
    "# print(metrics.accuracy_score(testY,predictedY))\r\n",
    "# print(metrics.recall_score(predictedY, testY,average = 'micro'))\r\n",
    "# print(metrics.precision_score(predictedY, testY,average = 'micro'))\r\n",
    "# print(metrics.f1_score(predictedY,testY,average = 'micro'))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loading data.....\n",
      "preprocessing data.....\n",
      "Learning model.....\n",
      "Classifying test data......\n",
      "Evaluating results.....\n",
      "The accuracy score is : -1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# P(ci) = [Num documents that have been classified as ci] / [Num documents]\r\n",
    "# where ci = a calss in label column\r\n",
    "\r\n",
    "# for P(a specific word / class j)\r\n",
    "# P ( wi | cj ) = [ count( wi, cj ) + 1 ] / [ Σw∈V( count ( w, cj ) ) + |V| ]\r\n",
    "# The probability of word i given class j is the count that the word occurred in documents of class j,\r\n",
    "# divided by the sum of the counts of each word in our vocabulary in class j refers the above probability.\r\n",
    "# So for the denominator, we iterate through each word in our vocabulary,\r\n",
    "# look up the frequency that it has occurred in class j, and add these up.\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "interpreter": {
   "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}